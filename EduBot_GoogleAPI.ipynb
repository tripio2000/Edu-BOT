{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d680b61",
   "metadata": {
    "id": "3d680b61"
   },
   "source": [
    "# Proyecto chatbot para Educacion\n",
    "\n",
    "Se propone el desarrollo de una prueba de concepto de un chatbot educativo que utilice la metodología RAG (Retrieval Augmented Generation) para responder de manera precisa a preguntas sobre el contenido de un curso universitario. Este chatbot, alimentado con las notas de clase de un curso existente, funcionará como un tutor virtual personalizado, disponible las 24 horas del día para los estudiantes. La iniciativa tiene como objetivo principal mejorar la experiencia de aprendizaje al proporcionar un recurso adicional para consultar el conocimiento contenido en los apuntes elaborados por los docentes. El chatbot será capaz de comprender preguntas complejas, encontrar la información relevante en las notas de clase y generar respuestas coherentes y concisas. Se utilizarán redes neuronales preentrenadas, de acceso abierto y alojadas de forma local en el servidor de la facultad. Para el desarrollo de la prueba de concepto se utilizará el lenguaje Python. El proyecto abarca desde la recopilación y procesamiento de las notas de clase en formato PDF, Word u otro formato similar, hasta el desarrollo de una interfaz conversacional intuitiva mediante la librería Streamlit o similar.\n",
    "Se espera que al utilizar el chatbot la consulta de los apuntes de clase por parte de los estudiantes aumente, de modo que se logre un aprendizaje más personalizado, una mayor comprensión de los conceptos y un ahorro de tiempo para los estudiantes. Además, se espera que este chatbot sea una herramienta valiosa para los docentes, al proporcionarles información sobre las áreas en las que los estudiantes tienen más interés o dificultades."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7273b0db",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "914ed62c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 760
    },
    "executionInfo": {
     "elapsed": 339,
     "status": "error",
     "timestamp": 1731552091240,
     "user": {
      "displayName": "Nicolas Tripp",
      "userId": "08255590174010293598"
     },
     "user_tz": 180
    },
    "id": "914ed62c",
    "outputId": "74f3da5f-8206-4689-d382-e1731c40e6c7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "#Retrieval libraries\n",
    "from unidecode import unidecode\n",
    "import re\n",
    "import torch\n",
    "from typing import List, Dict, Any\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "#from langchain.retrievers.document_compressors import FlashrankRerank\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "#from langchain_community.document_compressors import SentenceTransformerRerank\n",
    "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
    "from langchain.retrievers.document_compressors import EmbeddingsFilter # <-- Importar\n",
    "from langchain.retrievers.document_compressors import DocumentCompressorPipeline\n",
    "from langchain_community.document_transformers import EmbeddingsRedundantFilter\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "\n",
    "#LLM libraries\n",
    "from transformers import pipeline\n",
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ca1dec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded API Key.\n",
      "Key starts with: AIza... and ends with: ...CoTw\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "def get_api_key():\n",
    "    \"\"\"\n",
    "    Loads the LLM API key from the .env file and returns it.\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: If the LLM_API_KEY is not found in the environment.\n",
    "        \n",
    "    Returns:\n",
    "        str: The LLM API key.\n",
    "    \"\"\"\n",
    "    # This line loads the environment variables from the .env file\n",
    "    load_dotenv()\n",
    "    \n",
    "    # os.getenv() retrieves the value of the environment variable\n",
    "    api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "    \n",
    "    # This is a critical security and robustness check\n",
    "    if not api_key:\n",
    "        raise ValueError(\"API Key not found. Make sure you have a .env file with LLM_API_KEY defined.\")\n",
    "        \n",
    "    return api_key\n",
    "\n",
    "#####################################\n",
    "try:\n",
    "    my_llm_key = get_api_key()\n",
    "        \n",
    "        # Now you can use the key in your application\n",
    "    print(\"Successfully loaded API Key.\")\n",
    "        # For security, we only show the first and last few characters\n",
    "    print(f\"Key starts with: {my_llm_key[:4]}... and ends with: ...{my_llm_key[-4:]}\")\n",
    "        \n",
    "        # Example of using the key with a fictional API call\n",
    "        # some_llm_library.authenticate(api_key=my_llm_key)\n",
    "        \n",
    "except ValueError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "        \n",
    "os.environ[\"GOOGLE_API_KEY\"] = my_llm_key\n",
    "######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ea65470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cpu\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "# Chequeo dinámico de dispositivo (CPU o GPU)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Usando dispositivo: {device}\")\n",
    "\n",
    "# Use a specific folder to store the database, models, etc.\n",
    "PERSIST_DIRECTORY = \"./db_chroma\"\n",
    "MODEL_CACHE_DIR = \"./model_cache\"\n",
    "SOURCE_DOCS_PATH = \"./knowledgeBase\" \n",
    "\n",
    "# Define los parámetros de tu modelo de embedding\n",
    "model_name = 'BAAI/bge-m3'\n",
    "# Multi-Functionality: It can simultaneously perform the three common retrieval functionalities of embedding model: dense retrieval, multi-vector retrieval, and sparse retrieval.\n",
    "# Multi-Linguality: It can support more than 100 working languages.\n",
    "# Multi-Granularity: It is able to process inputs of different granularities, spanning from short sentences to long documents of up to 8192 tokens.\n",
    "\n",
    "model_kwargs = {'device': device}\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "\n",
    "# Crea la instancia del embedding encoder\n",
    "embedding_encoder = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs,\n",
    "    cache_folder=MODEL_CACHE_DIR\n",
    ")\n",
    "retrieval_reranker=HuggingFaceCrossEncoder(\n",
    "    model_name=\"BAAI/bge-reranker-v2-m3\"\n",
    "    #\"BAAI/bge-reranker-v2-m3\"\n",
    "    #\"BAAI/bge-reranker-v2-minicpm-layerwise\"\n",
    "    #\"Alibaba-NLP/gte-multilingual-reranker-base\" #General Text Embedding\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3dd000",
   "metadata": {},
   "source": [
    "## Funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b96907ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_markdown_document(file_path):\n",
    "    \"\"\"Loads a Markdown document and returns a LangChain Document object.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the Markdown file.\n",
    "\n",
    "    Returns:\n",
    "        langchain.document_loaders.TextLoader: A TextLoader object containing the document.\n",
    "    \"\"\"\n",
    "\n",
    "    loader = TextLoader(file_path,encoding=\"UTF8\")\n",
    "    documents = loader.load()\n",
    "\n",
    "    # Split documents by Markdown sections\n",
    "    headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "    (\"####\", \"Header 4\"),\n",
    "    ]\n",
    "    markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on, strip_headers=True)\n",
    "    md_header_splits = markdown_splitter.split_text(documents[0].page_content)\n",
    "    return md_header_splits\n",
    "\n",
    "# Helper function for printing docs\n",
    "def pretty_print_docs(docs):\n",
    "    print(\n",
    "        f\"\\n{'-' * 100}\\n\".join(\n",
    "            [f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "def EmbeddDocsAndPersist(all_splits,embedding_encoder,PERSIST_DIRECTORY):\n",
    "    # Crear embeddings y persistir la DB en disco\n",
    "    # Esto solo se hace una vez o cuando los documentos cambian\n",
    "    print(\"Creando y persistiendo la base de datos de vectores...\")\n",
    "    vectorStore = Chroma.from_documents(\n",
    "        documents=all_splits,\n",
    "        embedding=embedding_encoder,\n",
    "        persist_directory=PERSIST_DIRECTORY\n",
    "    )\n",
    "    print(\"Base de datos creada y guardada.\")\n",
    "    return vectorStore\n",
    "\n",
    "def load_persisted_db(embedding_encoder,PERSIST_DIRECTORY):\n",
    "    # Cargar la DB desde el disco\n",
    "    print(\"Cargando base de datos persistente...\")\n",
    "    vectorStore = Chroma(\n",
    "        persist_directory=PERSIST_DIRECTORY,\n",
    "        embedding_function=embedding_encoder\n",
    "    )\n",
    "    print(\"Base de datos cargada.\")\n",
    "    return vectorStore\n",
    "\n",
    "#Define a function for joining retrieved chunks\n",
    "def join_docs(docs):\n",
    "    return \"\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc1a2a8",
   "metadata": {},
   "source": [
    "## Inicilizacion de base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee8d8d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs = [] # <--- Lista para acumular todos los documentos\n",
    "\n",
    "for filename in os.listdir(SOURCE_DOCS_PATH): # <--- Iteramos sobre los archivos\n",
    "    if filename.endswith(\".md\"): # <--- Filtramos solo archivos .md\n",
    "        file_path = os.path.join(SOURCE_DOCS_PATH, filename) # <--- Construimos la ruta completa\n",
    "        processed_document_chunks = process_markdown_document(file_path) # <--- Procesamos cada archivo\n",
    "        all_docs.extend(processed_document_chunks) # <--- Agregamos los documentos\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, \n",
    "    chunk_overlap=100,\n",
    "    separators=[\"\\n\\n\", \"\\n\"])\n",
    "\n",
    "chunked_splits = text_splitter.split_documents(all_docs)\n",
    "\n",
    "# Add metadata\n",
    "for i, doc in enumerate(chunked_splits):\n",
    "    doc.metadata[\"doc_id\"] = f\"chunk_{i}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1ed5c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando base de datos persistente...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_293496/2031765100.py:48: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorStore = Chroma(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base de datos cargada.\n"
     ]
    }
   ],
   "source": [
    "#Codificacion de los chunks y Creacion de la base de datos\n",
    "if len(os.listdir(PERSIST_DIRECTORY))==0:\n",
    "    vectorStore = EmbeddDocsAndPersist(chunked_splits,embedding_encoder,PERSIST_DIRECTORY)\n",
    "else:\n",
    "    vectorStore = load_persisted_db(embedding_encoder,PERSIST_DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08a5d53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83e97d58883b4c98a0a8123f5fc92ba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/444 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67e0fe2207434d0faf2c5c7dff7c6cc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a85313f095de4ec1bd75bf8bd0bfe1ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "167c0f4642e041adb96f8a58e73b0952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: 'Un problema de **Valores y Vectores Propios** consiste en encontrar los vectores \\(v\\) tales que son direcciones invariantes de la transformación lineal dada por la matriz \\(A\\) (NxN). Esto se expresa como: \\(A v = \\lambda v \\) siendo \\(\\lambda\\) el escalar que cambia el módulo del vector cuya dirección permanece invariante. Se denomina **autovalor** \\( \\lambda \\) y **autovector** \\(v\\). El sistema de ecuaciones puede escribirse de la forma: \\((A - \\lambda I) v = 0 \\) donde interesan las soluciones \\(v\\) distintas de la trivial,\\(v = 0\\). Esto está garantizado sí y sólo sí \\(det(A - \\lambda I) = 0\\). El determinante constituye un polinomio de grado N en el autovalor \\(\\lambda \\), y se denomina **polinomio característico**. Las raíces de dicho polinomio son los autovalores \\(\\lambda \\) de la matriz \\(A\\) para los cuales existen los autovectores o direcciones invariantes \\(v\\). Por cada valor propio existe al menos una dirección invariante dada por el autovector \\(v\\).'\n",
      "Number of tokens: 329\n"
     ]
    }
   ],
   "source": [
    "#Calculo tokens por chunk para ver si se sobrecarga el LLM elegido para embedding\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load a pre-trained tokenizer (e.g., for BERT-base-uncased). BAAI/bge-m3\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "text = chunked_splits[0].page_content\n",
    "token_ids = tokenizer.encode(text)\n",
    "\n",
    "# The number of tokens is the length of the token_ids list\n",
    "num_tokens = len(token_ids)\n",
    "\n",
    "print(f\"Original text: '{text}'\")\n",
    "print(f\"Number of tokens: {num_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b08204a",
   "metadata": {},
   "source": [
    "## Testing Fase Retrieval\n",
    "\n",
    "### Armado de dataset de validacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a89cded5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Un problema de **Valores y Vectores Propios** consiste en encontrar los vectores \\(v\\) tales que son direcciones invariantes de la transformación lineal dada por la matriz \\(A\\) (NxN). Esto se expresa como: \\(A v = \\lambda v \\) siendo \\(\\lambda\\) el escalar que cambia el módulo del vector cuya dirección permanece invariante. Se denomina **autovalor** \\( \\lambda \\) y **autovector** \\(v\\). El sistema de ecuaciones puede escribirse de la forma: \\((A - \\lambda I) v = 0 \\) donde interesan las soluciones \\(v\\) distintas de la trivial,\\(v = 0\\). Esto está garantizado sí y sólo sí \\(det(A - \\lambda I) = 0\\). El determinante constituye un polinomio de grado N en el autovalor \\(\\lambda \\), y se denomina **polinomio característico**. Las raíces de dicho polinomio son los autovalores \\(\\lambda \\) de la matriz \\(A\\) para los cuales existen los autovectores o direcciones invariantes \\(v\\). Por cada valor propio existe al menos una dirección invariante dada por el autovector \\(v\\).' metadata={'Header 1': '1 INTRODUCCIÓN AL PROBLEMA', 'doc_id': 'chunk_0'}\n",
      "page_content='Existen diversos métodos para la determinación de los valores y vectores característicos, agrupados en las siguientes categorías:\n",
      "1. **Métodos de resolución del Polinomio Característico**: Consisten en encontrar las raíces del polinomio característico y, posteriormente, resolver el sistema homogéneo para cada valor propio obtenido como raíz. Es útil para sistemas de bajo orden (N pequeño), ya que a medida que N crece, también lo hace la dificultad para encontrar las raíces.\n",
      "2. **Métodos de Transformación**: Consisten en transformar la matriz \\(A\\) en una matriz diagonal mediante procesos de rotaciones y/o traslaciones. Entre los más eficaces se encuentran los métodos de Jacobi, Givens y Householder, que encuentran la totalidad de los valores y vectores propios.' metadata={'Header 1': '1 INTRODUCCIÓN AL PROBLEMA', 'doc_id': 'chunk_1'}\n",
      "page_content='3. **Métodos Iterativos**: Consisten en aproximar sucesivamente los valores y vectores propios. Generalmente, convergen a un valor y vector propio. Para encontrar más de uno, se recurre a técnicas de deflación para eliminar los ya conocidos. El método iterativo tratado en el curso es el **Método de la Potencia**.' metadata={'Header 1': '1 INTRODUCCIÓN AL PROBLEMA', 'doc_id': 'chunk_2'}\n",
      "page_content='Dada una matriz \\(A\\) (NxN), se asume que \\(\\lambda_i , v_i\\) son los autovalores y autovectores de \\(A\\) (el índice \\(i\\) varía de 1 a N). Se verifica que \\(A v_i = \\lambda_i v_i \\forall i = 1,...,N\\). Si \\(A\\) es diagonalizable, los \\( v_i\\) son linealmente independientes y forman una base. Cualquier vector \\(x\\) puede escribirse como una combinación lineal: \\(x = a_1 v_1 + a_2 v_2 + ... + a_N v_N\\). Al premultiplicar k veces el vector \\(x\\) por la matriz \\(A\\), se obtiene: \\(x_k = A^k x = a_1 \\lambda_1^k v_1 + a_2 \\lambda_2^k v_2 + ... + a_N \\lambda_N^k v_N\\) Esto puede reescribirse como: \\(x_k = \\lambda_1^k (a_1 v_1 + a_2 (\\lambda_2/\\lambda_1)^k v_2 + ... + a_N (\\lambda_N/\\lambda_1)^k v_N)\\) Asumiendo que \\(|\\lambda_1| > |\\lambda_2| \\geq ... \\geq |\\lambda_N|\\), se cumple que \\(lim_{k\\to\\inf} (\\lambda_i/\\lambda_1)^k = 0 , i \\neq 1\\). Esto significa que, a partir de cualquier vector, por sucesivas premultiplicaciones por \\(A\\), los vectores obtenidos se van alineando cada vez más con el **autovector dominante** \\(v_1\\). Así, \\(x_k \\approx \\lambda_1^k a_1 v_1\\) para k suficientemente grande. El cociente entre las componentes j del vector \\(x\\) en la iteracion k+1 y el vector en la interacion anterior k, es decir, \\(x_{k+1}(j) / x_k(j) \\) tiende al **autovalor dominante** \\(\\lambda_1\\). **Notas importantes:** - Hay **convergencia** al autovalor \\(\\lambda_1\\) de mayor valor absoluto. - Si \\(a_1 = 0\\), la convergencia no se produce o es muy lenta. - Para valores de iteracion k grandes, las componentes de \\(x_k\\) pueden ser muy grandes (si \\(|\\lambda_1| > 1\\)) o muy chicas (si \\(|\\lambda_1| < 1\\)), ya que son proporcionales a \\(\\lambda_1^k\\). Para evitar esto, se utiliza un **escalamiento** en cada iteración. Para realizar el escalamiento, se normaliza el vector \\(x\\) diviviendo por su norma, \\(x_n = x / ||x||\\) de manera que \\(||x_n|| = 1\\). El escalamiento en cada iteración asegura que las componentes de los vectores no aumenten (disminuyan) excesivamente, **asegurando la convergencia**.' metadata={'Header 1': '2 MÉTODO DE LA POTENCIA DIRECTA', 'doc_id': 'chunk_3'}\n",
      "page_content='Paso 1: **Lectura de datos**: Leer la matriz \\(A\\). Asumir un vector inicial \\(x\\). Leer un valor de tolerancia. Asignar un valor inicial al error.\n",
      "Paso 2: **Repetir mientras la medida de error supere la tolerancia**\n",
      "a.*Incrementar contador de iteraciones.\n",
      "b.*Cálculo de la Norma de \\(x\\).\n",
      "c.*Cálculo del vector normalizado \\(x_n\\).\n",
      "d.*Premultiplicar el vector normalizado por la matriz A \\(x  = A x_n\\).\n",
      "e.*Calcular los cocientes entre componentes de \\(x\\), \\(alfa(i) =x(i) / x_n(i)\\).\n",
      "f.*Calcular el error como la distancia maxima entre las componentes de alfa \\(max(alfa)-min(alfa)\\).\n",
      "Paso 3: **Entregar los resultados**:\n",
      "*El número de iteraciones realizadas fue k.\n",
      "*El autovector obtenido es \\(v = x / ||x||\\).\n",
      "*El mayor autovalor obtenido es \\(promedio(alfa)\\).' metadata={'Header 1': '2 MÉTODO DE LA POTENCIA DIRECTA', 'Header 2': '2.1 PSEUDOCODIGO DEL MÉTODO DE LA POTENCIA', 'doc_id': 'chunk_4'}\n",
      "page_content='Si la matriz `A` es diagonalizable, y `λ_i`, `v_i` son sus autovalores y autovectores, al premultiplicar a la ecuación `A v_i = λ_i v_i` por la matriz inversa `A^-1` (si existe), se obtiene `A^-1 v_i = (1/λ_i) v_i`. Esto significa que `1/λ_i` es un autovalor de `A^-1` asociado al mismo autovector `v_i`. El Método de la potencia aplicado sobre la matriz inversa `A^-1` converge al autovalor dominante de `A^-1`, que es el mayor `1/λ_i` tomado en valor absoluto. Esto implica que converge al menor `λ_i` de la matriz `A` (tomado en valor absoluto). Después de un número suficiente de iteraciones, el valor promedio de las componentes del vector `alfa` tiende a `1/λ_N` (si `λ_N` es el menor autovalor de `A` en valor absoluto). Los vectores se alinearán con el autovector `v_N` asociado. **Importante**: `x = A^-1 x_n` exige conocer `A^-1`. Para evitar su cálculo, el proceso iterativo se modifica a `A x = x_n`, que es un **sistema de ecuaciones lineales** que solo exige factorizar la matriz `A` una sola vez. Puede ser preferible factorizar `A` como `A = LU` al principio y por única vez. Luego, en cada paso, se resuelve `L z = x_n` mediante sustitución progresiva seguida de sustitución regresiva `U x = z`.' metadata={'Header 1': '3 MÉTODO DE LA POTENCIA INVERSA', 'doc_id': 'chunk_5'}\n",
      "page_content='Dado un vector cualquiera `x`, se puede escribir como combinación lineal de los autovectores `x = a_1 v_1 + a_2 v_2 + ... + a_N v_N`. Para obtener `a_1 = 0`, se puede proyectar `x` en la dirección de `v_1`. Si `A` es simétrica, sus autovectores `v_i` constituyen una base ortogonal. El proceso iterativo para modos intermedios se realiza reemplazando la matriz `A` por otra matriz `B` dada por: `B = A - (λ_1 / (||v_1||^2)) v_1 v_1^T` Cuando `k` es suficientemente grande, `alfa(i)` convergerá a `λ_2` y `x` se alineará con `v_2`. Este resultado, aunque mostrado para matrices simétricas, es válido para cualquier matriz diagonalizable bajo ciertas condiciones.' metadata={'Header 1': '4 CONVERGENCIA A MODOS INTERMEDIOS - DEFLACION', 'doc_id': 'chunk_6'}\n",
      "page_content='En diversas aplicaciones de la matemática, es fundamental calcular el valor de la **derivada de una función en un punto** o la **integral de una función** conocida analíticamente. Si bien estas operaciones suelen ser directas, pueden volverse complejas o difíciles de implementar computacionalmente en ciertas circunstancias.  \n",
      "El desafío se acentúa cuando la función se conoce de forma **discreta**. El objetivo de esta unidad es abordar el cálculo de **integrales definidas** de funciones dadas de forma analítica o discreta. Se asume que la función `y = f(x): R -> R` es **no singular** y **continua** (al menos por tramos) en el intervalo `[x0;xn]`.  \n",
      "Cuando `f(x)` se da de forma discreta (conocida en puntos `xi`, `i = 0,1,2,...,n`), es posible **interpolarla** con un polinomio `Pn(x)` de grado `n` que pase por `n+1` puntos datos. Si `f(x)` es analítica, se pueden \"extraer\" `n+1` puntos evaluando `f(x)` en `xi` para obtener `(xi; yi = f(xi))`.  \n",
      "La función `f(x)` puede expresarse como:' metadata={'Header 1': 'INTEGRACIÓN NUMÉRICA', 'Header 2': '1 ACERCA DE LOS PROBLEMAS DE LA INTEGRACIÓN Y LA DERIVACIÓN NUMÉRICAS EN GENERAL', 'doc_id': 'chunk_7'}\n",
      "page_content='La función `f(x)` puede expresarse como:\n",
      "`f(x) = Pn(x) + En(x)`\n",
      "Donde `En(x)` es el **error de interpolación**, dado por `(x-x0)...(x-xn) * f^(n+1)(xi) / (n+1)!`.\n",
      "Cualquier operador lineal `L[x]` (como la integral o la derivada) aplicado a `f(x)` resulta en:\n",
      "`L[f(x)] = L[Pn(x)] + L[En(x)]`.' metadata={'Header 1': 'INTEGRACIÓN NUMÉRICA', 'Header 2': '1 ACERCA DE LOS PROBLEMAS DE LA INTEGRACIÓN Y LA DERIVACIÓN NUMÉRICAS EN GENERAL', 'doc_id': 'chunk_8'}\n",
      "page_content='El objetivo principal es encontrar la **integral definida** `I` en `R`, dada por `I = Integral from X0 to Xn of f(x) dx`.\n",
      "Basándose en la relación `Integral(f(x)dx) = Integral(Pn(x)dx) + Integral(En(x)dx)`, la integral definida `I` se evalúa como la suma:\n",
      "`I = In + En`\n",
      "Donde `In` se denomina **cuadratura** y `En` es el **error de truncamiento**.  \n",
      "Todos los métodos de integración numérica comparten la estructura en la que la cuadratura `In` se expresa como una suma:\n",
      "`In = sum(wj * f(xj))`\n",
      "Los **coeficientes `wj`** se determinan según cada regla. El **orden de la regla de cuadratura** se define como el máximo grado del polinomio que dicha regla integra de forma exacta, es decir, para el cual `En = 0`.  \n",
      "Existen dos tipos principales de cuadratura:' metadata={'Header 1': 'INTEGRACIÓN NUMÉRICA', 'Header 2': '2 INTEGRACIÓN NUMÉRICA', 'doc_id': 'chunk_9'}\n",
      "page_content='En esta cuadratura, los **valores `xj`** donde se conoce `f(xj)` son **predeterminados** (datos fijos para la regla de integración). Los coeficientes `wj` se determinan para estos `xj`. El **paso** (distancia entre abscisas dato) puede ser fijo o variable.' metadata={'Header 1': 'INTEGRACIÓN NUMÉRICA', 'Header 2': '2 INTEGRACIÓN NUMÉRICA', 'Header 3': '2.1 Cuadratura de Newton-Cotes', 'doc_id': 'chunk_10'}\n",
      "page_content='En contraste con Newton-Cotes, tanto los **valores `xj` como los coeficientes `wj`** se determinan en cada regla de integración.' metadata={'Header 1': 'INTEGRACIÓN NUMÉRICA', 'Header 2': '2 INTEGRACIÓN NUMÉRICA', 'Header 3': '2.2 Cuadratura de Gauss-Legendre', 'doc_id': 'chunk_11'}\n",
      "page_content='Para una función `y = f(x): R -> R` dada en forma discreta mediante `n+1` puntos `(Xi ; Yi)`, `i = 0,...,n`, se utiliza un **polinomio de grado `n`** por el método de **polinomios de Lagrange**.\n",
      "`Pn(x) = sum(Yi * li(x))`\n",
      "Donde cada **polinomio base `li(x)`** es `product((x-xj)/(xi-xj))`.\n",
      "El grado del polinomio `Pn` y la cantidad de polinomios base `li(x)` dependen del número de puntos datos `(n+1)`.  \n",
      "La integral se expresa como `I = In + En`, donde:\n",
      "`In = Integral from X0 to Xn of Pn(x) dx = sum(Yi * Integral from X0 to Xn of li(x) dx)`\n",
      "`En = Integral from X0 to Xn of En(x) dx = Integral from X0 to Xn of (x-x0)...(x-xn) * f^(n+1)(xi) / (n+1)! dx`\n",
      "El **error `En`** es proporcional a la derivada de orden `(n+1)` de la función a integrar y al valor de la integral del primer polinomio (grado `n+1`) para el cual se comete error.  \n",
      "Los diferentes métodos surgen de interpolar mediante polinomios de distintos grados.' metadata={'Header 1': 'INTEGRACIÓN NUMÉRICA', 'Header 2': '3 REGLAS DE INTEGRACIÓN DE NEWTON - COTES', 'doc_id': 'chunk_12'}\n",
      "page_content='La **regla de los trapecios** es una regla de integración de **orden 1**, lo que significa que es exacta para polinomios de grado 1. Permite aproximar la integral `I` mediante la fórmula:\n",
      "`I = h/2 * (Yi + Yi+1) - h^3/12 * f''(xi)`\n",
      "Donde `xi` es un valor entre `xi` y `xi+1`.  \n",
      "Se exploran cuatro formas de desarrollo y cálculo del error para esta regla:' metadata={'Header 1': 'INTEGRACIÓN NUMÉRICA', 'Header 2': '3 REGLAS DE INTEGRACIÓN DE NEWTON - COTES', 'Header 3': '3.1 Regla de los Trapecios', 'doc_id': 'chunk_13'}\n",
      "page_content='Es una regla de Newton-Cotes que utiliza **2 puntos** `(xi;yi), (xi+1;yi+1)`. Se interpola la función `f(x)` mediante un polinomio de grado 1 (`P1(x)`).\n",
      "La fórmula resultante para el intervalo `[xi, xi+1]` es:\n",
      "`Ii = h/2 * (Yi + Yi+1)`\n",
      "Donde `h` es el paso `(xi+1 - xi)`.' metadata={'Header 1': 'INTEGRACIÓN NUMÉRICA', 'Header 2': '3 REGLAS DE INTEGRACIÓN DE NEWTON - COTES', 'Header 3': '3.1 Regla de los Trapecios', 'Header 4': '3.1.1 Desarrollo de la Regla de los Trapecios mediante Integración Del Polinomio Interpolante', 'doc_id': 'chunk_14'}\n",
      "page_content='El error `E1` al calcular la integral definida de `f(x)` entre `xa` y `xb` por el método de los trapecios se deriva de la integral del error de interpolación `E1(x)`.\n",
      "Al realizar un cambio de variable al dominio `t` en ``, se obtiene la expresión del error:\n",
      "`E1 = -h^3/12 * f''(xi)` para cierto punto `xi` en `(xa, xb)`.\n",
      "Se dice que el **error en la regla de trapecios es del orden de `h^3`: O(h^3)**. Es importante no confundir el orden de la regla de integración (1) con el orden del error (O(h^3)).' metadata={'Header 1': 'INTEGRACIÓN NUMÉRICA', 'Header 2': '3 REGLAS DE INTEGRACIÓN DE NEWTON - COTES', 'Header 3': '3.1 Regla de los Trapecios', 'Header 4': '3.1.2 Cálculo del Error en la Regla De Trapecios a partir del Error de Interpolación', 'doc_id': 'chunk_15'}\n",
      "page_content='Partiendo de la definición `E1 = I - I1` y desarrollando la función primitiva `G(x)` en serie de Taylor alrededor de `xi`, se confirma que el **error en la regla de trapecios es O(h^3)**.' metadata={'Header 1': 'INTEGRACIÓN NUMÉRICA', 'Header 2': '3 REGLAS DE INTEGRACIÓN DE NEWTON - COTES', 'Header 3': '3.1 Regla de los Trapecios', 'Header 4': '3.1.3 Cálculo Del Error De La Regla De Los Trapecios usando Serie De Taylor', 'doc_id': 'chunk_16'}\n",
      "page_content='Este método busca determinar los coeficientes `a0` y `a1` de la expresión `Integral(G(t)dt) = a0*G(0) + a1*G(1) + R` (donde R es el error) de manera que la regla sea exacta para las funciones `{1, t}`.\n",
      "Se obtiene `a0 = a1 = 1/2`.\n",
      "El error de truncamiento `R` se determina aplicando la regla a polinomios de grado superior (cuadráticos, en este caso). Se llega a que `R = -h^2/12 * f''(xi)`.\n",
      "La regla de los trapecios completa es:\n",
      "`Integral from Xi to Xi+1 of f(x) dx = h/2 * (Yi + Yi+1) - h^3/12 * f''(xi)`.  \n",
      "**Ejemplo:** `f(x) = sen(x)`. Integrando de `0` a `pi/2` (exacto = 1) y de `0` a `pi` (exacto = 2).\n",
      "Para `h = pi/2`: `I1 = pi/4 = 0.7854`.\n",
      "Para `h = pi`: `I1 = 0`.' metadata={'Header 1': 'INTEGRACIÓN NUMÉRICA', 'Header 2': '3 REGLAS DE INTEGRACIÓN DE NEWTON - COTES', 'Header 3': '3.1 Regla de los Trapecios', 'Header 4': '3.1.4 Regla De Los Trapecios Por El Método De Los Coeficientes Indeterminados', 'doc_id': 'chunk_17'}\n",
      "page_content='Para calcular `Integral from X0 to Xn of f(x) dx`, el intervalo `[x0; xn]` se divide en `n` subintervalos `[x0; x1], [x1; x2], ..., [xn-1; xn]`. Se aplica la regla de los trapecios simple en cada subintervalo y se suman los resultados.\n",
      "Si todos los intervalos tienen la misma longitud `h`, la fórmula se simplifica a la **regla de trapecios múltiple**:\n",
      "`I = h/2 * (Y0 + 2*sum(Yi for i=1 to n-1) + Yn) + E1M`\n",
      "Donde `E1M` es el error total acumulado.  \n",
      "El **error `E1M`** se aproxima como:\n",
      "`E1M = - (xn - x0) * h^2/12 * f''(xi)`\n",
      "El **orden del error** para la regla de trapecios múltiple es `O(h^2)`. Al pasar de la regla simple (O(h^3)) a la compuesta (O(h^2)), la precisión disminuye.' metadata={'Header 1': 'INTEGRACIÓN NUMÉRICA', 'Header 2': '3 REGLAS DE INTEGRACIÓN DE NEWTON - COTES', 'Header 3': '3.2 Regla De Los Trapecios Múltiple o Trapecios Compuesta', 'doc_id': 'chunk_18'}\n",
      "page_content='Se presentan pseudo-códigos para la implementación de la regla de trapecios múltiples, tanto para funciones dadas en **forma discreta** (tabla de valores x, y) como para funciones dadas en **forma analítica**.  \n",
      "*   **Algoritmo trapecios-múltiples-discreta:** Lee valores X e Y, calcula la suma ponderada de Y, determina `h` y la integral final.\n",
      "*   **Algoritmo Trapecios-múltiples-Equidistante-analítica:** Define la función `f(x)`, calcula `h`, y suma los valores de `f(x)` ponderados.' metadata={'Header 1': 'INTEGRACIÓN NUMÉRICA', 'Header 2': '3 REGLAS DE INTEGRACIÓN DE NEWTON - COTES', 'Header 3': '3.3 Algoritmo De Trapecios Múltiples', 'doc_id': 'chunk_19'}\n",
      "page_content='La **regla de Simpson** es una regla de **orden 3**, lo que significa que integra de forma exacta polinomios de grado hasta 3. Permite aproximar la integral `I` mediante la fórmula:\n",
      "`I = h/3 * (f(x0) + 4*f(x1) + f(x2)) - h^5/90 * f^(4)(xi)`\n",
      "Donde `xi` es un valor entre `x0` y `x2`.' metadata={'Header 1': 'INTEGRACIÓN NUMÉRICA', 'Header 2': '3 REGLAS DE INTEGRACIÓN DE NEWTON - COTES', 'Header 3': '3.4 Regla de Simpson', 'doc_id': 'chunk_20'}\n",
      "page_content='Es una cuadratura de Newton-Cotes con `n=2`, es decir, utiliza **tres puntos**. Se interpola la función con un polinomio de Lagrange de grado dos y se integra este polinomio de forma aproximada.\n",
      "Si los intervalos son iguales (`h1 = h2 = h`), la fórmula de Simpson es:\n",
      "`I = h/3 * (Y0 + 4*Y1 + Y2)`' metadata={'Header 1': 'INTEGRACIÓN NUMÉRICA', 'Header 2': '3 REGLAS DE INTEGRACIÓN DE NEWTON - COTES', 'Header 3': '3.4 Regla de Simpson', 'Header 4': '3.4.1 Regla de Simpson mediante integración del polinomio interpolante', 'doc_id': 'chunk_21'}\n",
      "page_content='Se busca normalizar la integral al dominio `t` en `[-1, 1]`. Se propone resolver la integral de `G(t)` con coeficientes indeterminados `C-1, C0, C1` de manera que la regla sea exacta para `{1, t, t^2}`.\n",
      "Se obtienen los coeficientes: `C-1 = 1/3`, `C0 = 4/3`, `C1 = 1/3`.\n",
      "Esto lleva a la misma fórmula: `I = h/3 * (Y0 + 4*Y1 + Y2)`.' metadata={'Header 1': 'INTEGRACIÓN NUMÉRICA', 'Header 2': '3 REGLAS DE INTEGRACIÓN DE NEWTON - COTES', 'Header 3': '3.4 Regla de Simpson', 'Header 4': '3.4.2 Regla De Simpson Por El Método De Los Coeficientes Indeterminados', 'doc_id': 'chunk_22'}\n",
      "page_content='El error de truncamiento `R` se determina aplicando la regla a polinomios de grado superior. Se encuentra que la regla es exacta incluso para polinomios de grado 3. Para polinomios de grado 4, se obtiene el error:\n",
      "`R = -h^5/90 * f^(4)(xi)`\n",
      "El **orden del error** para la regla de Simpson es **`O(h^5)`**.' metadata={'Header 1': 'INTEGRACIÓN NUMÉRICA', 'Header 2': '3 REGLAS DE INTEGRACIÓN DE NEWTON - COTES', 'Header 3': '3.4 Regla de Simpson', 'Header 4': '3.4.3 Regla de Simpson - error', 'doc_id': 'chunk_23'}\n",
      "page_content='La regla de Simpson compuesta se obtiene sumando aplicaciones sucesivas de la regla de Simpson simple. La fórmula es:\n",
      "`I = h/3 * (f(x0) + 4*sum(f(xi) for odd i) + 2*sum(f(xi) for even i) + f(xn))`\n",
      "Similar a la regla de los trapecios, al pasar de la regla de Simpson simple (O(h^5)) a la compuesta, el **orden del error disminuye** a **`O(h^4)`**.' metadata={'Header 1': 'INTEGRACIÓN NUMÉRICA', 'Header 2': '3 REGLAS DE INTEGRACIÓN DE NEWTON - COTES', 'Header 3': '3.5 Regla de Simpson Compuesta', 'doc_id': 'chunk_24'}\n",
      "page_content='En la **cuadratura de Gauss**, el problema se plantea en el **dominio unitario `[-1, 1]`**. Este método busca determinar tanto los coeficientes como los puntos de evaluación de la función. La idea es hallar los valores de abscisas `t1, t2, ...` y coeficientes `w1, w2, ...` para aproximar la integral `Integral from -1 to 1 of G(t) dt`.' metadata={'Header 1': 'INTEGRACIÓN NUMÉRICA', 'Header 2': '4 CUADRATURA DE GAUSS', 'doc_id': 'chunk_25'}\n",
      "page_content='Para la regla de dos puntos, se proponen `w1*G(t1) + w2*G(t2)`. Los valores `w1, w2, t1, t2` se determinan de manera que el error de integración sea `R = 0` para polinomios de hasta 3er grado.\n",
      "Las soluciones son: `t1 = -1/sqrt(3)`, `t2 = 1/sqrt(3)`, `w1 = 1`, `w2 = 1`.\n",
      "La regla queda: `I = h * (f(c - h/sqrt(3)) + f(c + h/sqrt(3)))`.' metadata={'Header 1': 'INTEGRACIÓN NUMÉRICA', 'Header 2': '4 CUADRATURA DE GAUSS', 'Header 4': '4.1 Regla De Dos Puntos Usando el Método De Coeficientes Indeterminados', 'doc_id': 'chunk_26'}\n",
      "page_content='La regla de dos puntos se puede generalizar a más puntos. Se proporciona una tabla con las abscisas (`ti`) y coeficientes (`wi`) para 2, 3 y 4 puntos de Gauss, y el orden de la derivada del error de truncamiento.  \n",
      "*   **2 puntos:** Abscisas `+-0.577350269`, Coeficientes `1.0`, Orden de error `4`.\n",
      "*   **3 puntos:** Abscisas `0`, `+-0.774596669`, Coeficientes `0.8888889`, `0.5555556`, Orden de error `6`.\n",
      "*   **4 puntos:** Abscisas `+-0.339981044`, `+-0.861136312`, Coeficientes `0.6521452`, `0.3478548`, Orden de error `8`.' metadata={'Header 1': 'INTEGRACIÓN NUMÉRICA', 'Header 2': '4 CUADRATURA DE GAUSS', 'Header 4': '4.2 Generalización de la regla anterior', 'doc_id': 'chunk_27'}\n",
      "page_content='La **extrapolación de Richardson** es una técnica para **mejorar la aproximación de una integral** (o derivada) cuando se tienen dos aproximaciones obtenidas con pasos diferentes (`h1` y `h2`).\n",
      "Si una regla tiene un error del orden de `h^n`, y `h2 = h1 / R` (donde R es un factor), la mejorada integral `I_mejorado` se calcula como:\n",
      "`I_mejorado = (R^n * I(h_small) - I(h_large)) / (R^n - 1)`\n",
      "El error de la nueva aproximación es de un orden superior. Por ejemplo, para la regla de trapecios compuesta (error `O(h^2)`), la extrapolación de Richardson da un error `O(h^4)`. Para la regla de Simpson compuesta (error `O(h^4)`), el error resultante es `O(h^6)`.' metadata={'Header 1': 'INTEGRACIÓN NUMÉRICA', 'Header 2': '5 EXTRAPOLACIÓN DE RICHARDSON', 'doc_id': 'chunk_28'}\n",
      "page_content='La **integración de Romberg** es un método que aplica **sucesivas extrapolaciones de Richardson** sobre una serie de aproximaciones obtenidas con la **regla de trapecios múltiples**, utilizando pasos que se reducen a la mitad.\n",
      "La fórmula general para las mejoras es:\n",
      "`Ij,k = (4^(k-1) * Ij+1,k-1 - Ij,k-1) / (4^(k-1) - 1)`\n",
      "Donde `j` es el nivel de divisiones por la mitad del paso original y `k` indica el nivel de extrapolación.\n",
      "El criterio de parada para las iteraciones es que la diferencia relativa entre aproximaciones consecutivas sea menor que una tolerancia `Epsilon` o que se alcance un número máximo de iteraciones.' metadata={'Header 1': 'INTEGRACIÓN NUMÉRICA', 'Header 2': '6 INTEGRACIÓN DE ROMBERG', 'doc_id': 'chunk_29'}\n",
      "page_content='Se presenta un pseudo-código para la integración de Romberg. Este algoritmo calcula las aproximaciones trapezoidales para diferentes pasos (`h`), y luego aplica las extrapolaciones de Richardson en cascada para obtener una solución mejorada.  \n",
      "**Ejemplo:** Integración de `sen(x)` de `0` a `pi`. Se muestra una tabla que ilustra cómo las aproximaciones mejoran con cada nivel de extrapolación, reduciendo el orden del error progresivamente de `O(h^2)` a `O(h^12)`.' metadata={'Header 1': 'INTEGRACIÓN NUMÉRICA', 'Header 2': '6 INTEGRACIÓN DE ROMBERG', 'Header 3': '6.1 Algoritmo de Romberg', 'doc_id': 'chunk_30'}\n"
     ]
    }
   ],
   "source": [
    "#Observamos chunks para armar evaluation_dataset\n",
    "for i, doc in enumerate(chunked_splits):\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aec1e208",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejemplo de resultado para guiar la IA generativa\n",
    "evaluation_dataset = [\n",
    "    {\n",
    "        \"question\": \"¿Cuál es la condición de convergencia para el método de la potencia?\",\n",
    "        \"ground_truth_doc_id\": \"chunk_3\" # The ID of the paragraph with the answer\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"¿Cuál es el pseudocodigo del método de la potencia?\",\n",
    "        \"ground_truth_doc_id\": \"chunk_4\"\n",
    "    },\n",
    "    \n",
    "    #COMPLETAR CASOS\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d11f1e9",
   "metadata": {},
   "source": [
    "> Usamos IA generativa externa para crear casos de validacion a partir de los chunks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d75b8b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_dataset_AIgenerated = [\n",
    "    {\n",
    "        \"question\": \"¿Qué es un autovector y un autovalor?\",\n",
    "        \"ground_truth_doc_id\": \"chunk_0\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"¿Qué es el polinomio característico y cómo se relaciona con los autovalores?\",\n",
    "        \"ground_truth_doc_id\": \"chunk_0\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Menciona las tres categorías de métodos para la determinación de valores y vectores característicos.\",\n",
    "        \"ground_truth_doc_id\": \"chunk_1\" \n",
    "    },\n",
    "    {\n",
    "        \"question\": \"¿En qué consisten los métodos iterativos para encontrar autovalores y cuál es el ejemplo tratado en el curso?\",\n",
    "        \"ground_truth_doc_id\": \"chunk_2\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"¿Cuál es la condición de convergencia para el método de la potencia directa?\",\n",
    "        \"ground_truth_doc_id\": \"chunk_3\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"¿Por qué es necesario usar escalamiento en el método de la potencia y cómo se realiza?\",\n",
    "        \"ground_truth_doc_id\": \"chunk_3\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"¿Cuál es el pseudocodigo del método de la potencia?\",\n",
    "        \"ground_truth_doc_id\": \"chunk_4\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"¿Cómo funciona el método de la potencia inversa y a qué autovalor de la matriz original converge?\",\n",
    "        \"ground_truth_doc_id\": \"chunk_5\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"¿Qué es la deflación y para qué se utiliza en el cálculo de autovectores?\",\n",
    "        \"ground_truth_doc_id\": \"chunk_6\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"¿Qué es la cuadratura y el error de truncamiento en la integración numérica?\",\n",
    "        \"ground_truth_doc_id\": \"chunk_9\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"¿Cuál es la diferencia fundamental entre la cuadratura de Newton-Cotes y la de Gauss-Legendre?\",\n",
    "        \"ground_truth_doc_id\": \"chunk_11\" # This chunk explicitly contrasts with Newton-Cotes described in chunk_10\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"¿Qué es la regla de los trapecios y cuál es su orden de exactitud?\",\n",
    "        \"ground_truth_doc_id\": \"chunk_13\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"¿Cuál es el orden del error en la regla de los trapecios simple?\",\n",
    "        \"ground_truth_doc_id\": \"chunk_15\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"¿Cómo cambia el orden del error al pasar de la regla de trapecios simple a la múltiple?\",\n",
    "        \"ground_truth_doc_id\": \"chunk_18\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"¿Cuál es la fórmula de la regla de Simpson simple y cuántos puntos utiliza?\",\n",
    "        \"ground_truth_doc_id\": \"chunk_21\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"¿Cuál es el orden del error para la regla de Simpson simple?\",\n",
    "        \"ground_truth_doc_id\": \"chunk_23\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"¿Cuál es la fórmula de la regla de Simpson compuesta y cuál es el orden de su error?\",\n",
    "        \"ground_truth_doc_id\": \"chunk_24\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Describe la regla de cuadratura de Gauss de dos puntos, incluyendo los valores de las abscisas y los coeficientes.\",\n",
    "        \"ground_truth_doc_id\": \"chunk_26\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"¿Qué es la extrapolación de Richardson y cuál es su propósito?\",\n",
    "        \"ground_truth_doc_id\": \"chunk_28\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"¿En qué consiste la integración de Romberg y qué técnica aplica sucesivamente?\",\n",
    "        \"ground_truth_doc_id\": \"chunk_29\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6335e66e",
   "metadata": {},
   "source": [
    "### Testing vectorstore as retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65b3d87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_vectorstore_as_retriever(eval_dataset, vector_store, k=5):\n",
    "    \"\"\"\n",
    "    Evaluates the performance of a retriever using a given dataset.\n",
    "\n",
    "    Args:\n",
    "        eval_dataset (list): A list of dictionaries with \"question\" and \"ground_truth_doc_id\".\n",
    "        vector_store: The ChromaDB vector store instance.\n",
    "        k (int): The number of top documents to retrieve for evaluation.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the calculated metrics.\n",
    "    \"\"\"\n",
    "    hits = 0\n",
    "    reciprocal_ranks = []\n",
    "    misses = [] # To store information about failed queries for later analysis\n",
    "\n",
    "    print(f\"Starting evaluation for k={k}...\")\n",
    "\n",
    "    for item in eval_dataset:\n",
    "        question = item[\"question\"]\n",
    "        ground_truth_id = item[\"ground_truth_doc_id\"]\n",
    "        \n",
    "        # Perform the similarity search\n",
    "        # The result is a list of tuples: [(Document, score), (Document, score), ...]\n",
    "        retrieved_docs_with_scores = vector_store.similarity_search_with_score(question, k=k)\n",
    "        \n",
    "        # Extract the doc_ids from the metadata of the retrieved documents\n",
    "        retrieved_ids = [doc.metadata.get('doc_id') for doc, score in retrieved_docs_with_scores]\n",
    "        \n",
    "        # Check if the ground truth ID is in the retrieved IDs\n",
    "        if ground_truth_id in retrieved_ids:\n",
    "            hits += 1\n",
    "            # Find the rank (position) of the correct document. Ranks are 1-based.\n",
    "            rank = retrieved_ids.index(ground_truth_id) + 1\n",
    "            reciprocal_ranks.append(1 / rank)\n",
    "        else:\n",
    "            reciprocal_ranks.append(0)\n",
    "            misses.append({\n",
    "                \"question\": question,\n",
    "                \"expected\": ground_truth_id,\n",
    "                \"retrieved\": retrieved_ids\n",
    "            })\n",
    "\n",
    "    total_questions = len(eval_dataset)\n",
    "    hit_rate = (hits / total_questions) * 100\n",
    "    mrr = np.mean(reciprocal_ranks)\n",
    "\n",
    "    return {\n",
    "        \"hit_rate_at_k\": k,\n",
    "        \"hit_rate\": f\"{hit_rate:.2f}%\",\n",
    "        \"mrr\": f\"{mrr:.4f}\",\n",
    "        \"total_questions\": total_questions,\n",
    "        \"hits\": hits,\n",
    "        \"misses_count\": len(misses),\n",
    "        \"misses\": misses\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72eeb34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation for k=5...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate_at_k': 5,\n",
       " 'hit_rate': '85.00%',\n",
       " 'mrr': '0.6917',\n",
       " 'total_questions': 20,\n",
       " 'hits': 17,\n",
       " 'misses_count': 3,\n",
       " 'misses': [{'question': '¿Cuál es la condición de convergencia para el método de la potencia directa?',\n",
       "   'expected': 'chunk_3',\n",
       "   'retrieved': ['chunk_5', 'chunk_17', 'chunk_27', 'chunk_26', 'chunk_13']},\n",
       "  {'question': '¿Cuál es el pseudocodigo del método de la potencia?',\n",
       "   'expected': 'chunk_4',\n",
       "   'retrieved': ['chunk_19', 'chunk_30', 'chunk_5', 'chunk_12', 'chunk_17']},\n",
       "  {'question': '¿Qué es la deflación y para qué se utiliza en el cálculo de autovectores?',\n",
       "   'expected': 'chunk_6',\n",
       "   'retrieved': ['chunk_3', 'chunk_5', 'chunk_0', 'chunk_2', 'chunk_4']}]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_vectorstore_as_retriever(evaluation_dataset_AIgenerated, vectorStore, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "853b01d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation for k=3...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate_at_k': 3,\n",
       " 'hit_rate': '75.00%',\n",
       " 'mrr': '0.6667',\n",
       " 'total_questions': 20,\n",
       " 'hits': 15,\n",
       " 'misses_count': 5,\n",
       " 'misses': [{'question': '¿Cuál es la condición de convergencia para el método de la potencia directa?',\n",
       "   'expected': 'chunk_3',\n",
       "   'retrieved': ['chunk_5', 'chunk_17', 'chunk_27']},\n",
       "  {'question': '¿Cuál es el pseudocodigo del método de la potencia?',\n",
       "   'expected': 'chunk_4',\n",
       "   'retrieved': ['chunk_19', 'chunk_30', 'chunk_5']},\n",
       "  {'question': '¿Qué es la deflación y para qué se utiliza en el cálculo de autovectores?',\n",
       "   'expected': 'chunk_6',\n",
       "   'retrieved': ['chunk_3', 'chunk_5', 'chunk_0']},\n",
       "  {'question': '¿Cuál es la diferencia fundamental entre la cuadratura de Newton-Cotes y la de Gauss-Legendre?',\n",
       "   'expected': 'chunk_11',\n",
       "   'retrieved': ['chunk_21', 'chunk_25', 'chunk_14']},\n",
       "  {'question': 'Describe la regla de cuadratura de Gauss de dos puntos, incluyendo los valores de las abscisas y los coeficientes.',\n",
       "   'expected': 'chunk_26',\n",
       "   'retrieved': ['chunk_27', 'chunk_25', 'chunk_10']}]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_vectorstore_as_retriever(evaluation_dataset_AIgenerated, vectorStore, k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af09b8a4",
   "metadata": {},
   "source": [
    "### Testing de Re-ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a07c7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el retriever base. Este será \"envuelto\" por el compresor.\n",
    "# Le damos un 'k' más alto porque esperamos que el filtro descarte algunos resultados.\n",
    "base_retriever = vectorStore.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\", \n",
    "    search_kwargs={\"score_threshold\": 0.1,\"k\": 10}\n",
    "    #search_type=\"similarity\", # 'similarity' with a 'k' is often more reliable\n",
    "    #search_kwargs={\"k\": 10} # Retrieve more documents to give the reranker more to work with\n",
    ")\n",
    "# ¡IMPORTANTE! Usamos la MISMA instancia 'embedding_encoder' que para la DB.\n",
    "redundant_filter = EmbeddingsRedundantFilter(embeddings=embedding_encoder)\n",
    "reranker = CrossEncoderReranker(model=retrieval_reranker, top_n=3)\n",
    "pipeline_compressor = DocumentCompressorPipeline(\n",
    "    transformers=[redundant_filter, reranker]\n",
    ")\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=pipeline_compressor, \n",
    "    base_retriever=base_retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e97da77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_retriever(\n",
    "    retriever: Any,\n",
    "    eval_dataset: List[Dict[str, str]],\n",
    "    retriever_name: str\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Evaluates the performance of any retriever with a .invoke() method.\n",
    "\n",
    "    Args:\n",
    "        retriever (Any): A retriever object that has an .invoke(query) method\n",
    "                         which returns a list of Document objects.\n",
    "        eval_dataset (list): A list of dictionaries with \"question\" and \n",
    "                             \"ground_truth_doc_id\".\n",
    "        retriever_name (str): A descriptive name for the retriever being tested\n",
    "                              (e.g., \"Base Retriever k=5\").\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the calculated metrics and a list of misses.\n",
    "    \"\"\"\n",
    "    hits = 0\n",
    "    reciprocal_ranks = []\n",
    "    misses = []  # To store information about failed queries for analysis\n",
    "\n",
    "    print(f\"--- Starting evaluation for: {retriever_name} ---\")\n",
    "\n",
    "    for item in eval_dataset:\n",
    "        question = item[\"question\"]\n",
    "        ground_truth_id = item[\"ground_truth_doc_id\"]\n",
    "        \n",
    "        # 1. Use the generic .invoke() method\n",
    "        retrieved_docs = retriever.invoke(question)\n",
    "        \n",
    "        # 2. Extract doc_ids from the list of Document objects\n",
    "        retrieved_ids = [doc.metadata.get('doc_id') for doc in retrieved_docs]\n",
    "        \n",
    "        # 3. Perform the evaluation logic (this part remains the same)\n",
    "        if ground_truth_id in retrieved_ids:\n",
    "            hits += 1\n",
    "            # Ranks are 1-based\n",
    "            rank = retrieved_ids.index(ground_truth_id) + 1\n",
    "            reciprocal_ranks.append(1 / rank)\n",
    "        else:\n",
    "            reciprocal_ranks.append(0)\n",
    "            misses.append({\n",
    "                \"question\": question,\n",
    "                \"expected\": ground_truth_id,\n",
    "                \"retrieved\": retrieved_ids\n",
    "            })\n",
    "\n",
    "    total_questions = len(eval_dataset)\n",
    "    hit_rate = (hits / total_questions) * 100\n",
    "    mrr = np.mean(reciprocal_ranks) if reciprocal_ranks else 0\n",
    "\n",
    "    print(f\"Evaluation finished for: {retriever_name}\\n\")\n",
    "\n",
    "    return {\n",
    "        \"retriever_name\": retriever_name,\n",
    "        \"hit_rate\": f\"{hit_rate:.2f}%\",\n",
    "        \"mrr\": f\"{mrr:.4f}\",\n",
    "        \"total_questions\": total_questions,\n",
    "        \"hits\": hits,\n",
    "        \"misses_count\": len(misses),\n",
    "        \"misses\": misses\n",
    "    }\n",
    "\n",
    "def print_results(results: Dict[str, Any]):\n",
    "    \"\"\"Helper function to print evaluation results in a readable format.\"\"\"\n",
    "    print(f\"--- Retrieval Evaluation Results for: {results['retriever_name']} ---\")\n",
    "    print(f\"Hit Rate: {results['hit_rate']}\")\n",
    "    print(f\"Mean Reciprocal Rank (MRR): {results['mrr']}\")\n",
    "    print(f\"Correctly Retrieved (Hits): {results['hits']} / {results['total_questions']}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    if results['misses_count'] > 0:\n",
    "        print(f\"\\nAnalysis of {results['misses_count']} Misses:\")\n",
    "        # Print details for the first 3 misses for brevity\n",
    "        for i, miss in enumerate(results['misses'][:3]):\n",
    "            print(f\"\\nMiss {i+1}:\")\n",
    "            print(f\"  Question: '{miss['question']}'\")\n",
    "            print(f\"  Expected Doc ID: {miss['expected']}\")\n",
    "            print(f\"  Retrieved IDs:   {miss['retrieved']}\")\n",
    "        if results['misses_count'] > 3:\n",
    "            print(\"\\n(And more...)\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e0ebd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting evaluation for: Base Retriever ---\n",
      "Evaluation finished for: Base Retriever\n",
      "\n",
      "--- Starting evaluation for: Compression Retriever ---\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the base retriever\n",
    "base_retriever_results = evaluate_retriever(\n",
    "    retriever=base_retriever,\n",
    "    eval_dataset=evaluation_dataset_AIgenerated,\n",
    "    retriever_name=\"Base Retriever\"\n",
    ")\n",
    "# Evaluate the compression retriever\n",
    "compression_retriever_results = evaluate_retriever(\n",
    "    retriever=compression_retriever,\n",
    "    eval_dataset=evaluation_dataset_AIgenerated,\n",
    "    retriever_name=\"Compression Retriever\"\n",
    ")\n",
    "\n",
    "# --- Reporting Phase ---\n",
    "print_results(base_retriever_results)\n",
    "print_results(compression_retriever_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f093560c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Retrieval Evaluation Results for: Base Retriever ---\n",
      "Hit Rate: 95.00%\n",
      "Mean Reciprocal Rank (MRR): 0.7083\n",
      "Correctly Retrieved (Hits): 19 / 20\n",
      "--------------------------------------------------\n",
      "\n",
      "Analysis of 1 Misses:\n",
      "\n",
      "Miss 1:\n",
      "  Question: '¿Cuál es el pseudocodigo del método de la potencia?'\n",
      "  Expected Doc ID: chunk_4\n",
      "  Retrieved IDs:   ['chunk_19', 'chunk_30', 'chunk_5', 'chunk_12', 'chunk_17', 'chunk_21', 'chunk_2', 'chunk_14', 'chunk_28', 'chunk_27']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_results(base_retriever_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8007dc1f",
   "metadata": {},
   "source": [
    "## Setup Fase Generativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8966e361",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadGoogleLLM():\n",
    "    \"\"\"Instantiates and returns a Google LLM through the LangChain interface.\"\"\"\n",
    "    # Ensure your GOOGLE_API_KEY is set as an environment variable\n",
    "    llm = ChatGoogleGenerativeAI(model=\"gemma-3-27b-it\", temperature=0)\n",
    "    return llm\n",
    "\n",
    "def DefineGemmaPrompt():\n",
    "    \"\"\"\n",
    "    Defines the prompt template for Gemma 3 models via Google API.\n",
    "    \n",
    "    Since Gemma 3 does not support system prompts through this API, this function\n",
    "    combines the system instructions and the user query into a single human/user\n",
    "    message template.\n",
    "    \"\"\"\n",
    "    system_instructions = \"\"\"Eres un experto en pedagogía para estudiantes universitarios de la generación Z y profesor de la cátedra de Métodos Numéricos en la Facultad de Ingeniería. Tu objetivo es guiar al usuario a lograr una comprensión más profunda sobre su pregunta.\n",
    "\n",
    "Recibirás una PREGUNTA y un CONTEXTO de las notas de clase. Sigue estas reglas estrictamente:\n",
    "1. Responde a la PREGUNTA utilizando ÚNICAMENTE el CONTEXTO proporcionado. No uses información de otras fuentes. Si no hay CONTEXTO, indica que la respuesta no ha sido encontrada.\n",
    "2. Formatea siempre tus respuestas utilizando Markdown para mejorar la legibilidad.\n",
    "3. Después de tu explicación, incluye una sección de TAREAS ACCIONABLES o PREGUNTAS DE REFLEXIÓN para que el estudiante aplique o profundice su conocimiento.\n",
    "4. Responde siempre en español. Sé útil y claro.\"\"\"\n",
    "\n",
    "    # Combine the instructions and the dynamic parts into a single template string.\n",
    "    # The model will treat the entire block as the user's input.\n",
    "    full_prompt_string = (\n",
    "        f\"{system_instructions}\\n\\n\"\n",
    "        \"--- \\n\\n\"  # Using a separator can sometimes help the model distinguish instructions from data.\n",
    "        \"CONTEXTO:\\n{context}\\n\\n\"\n",
    "        \"PREGUNTA:\\n{question}\"\n",
    "    )\n",
    "\n",
    "    # Create the template from a single string. LangChain will treat this\n",
    "    # as a single \"human\" message by default in many chains.\n",
    "    prompt_template = ChatPromptTemplate.from_template(full_prompt_string)\n",
    "    \n",
    "    return prompt_template\n",
    "\n",
    "def ProcessInput(question,retriever,llm):\n",
    "    #Data pipeline: user query->retrieve chunks->join them->inject in prompt-> get LLM response\n",
    "    prompt = DefineGemmaPrompt()\n",
    "    rag_chain = (\n",
    "        {\"context\": retriever | join_docs, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    return rag_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5362deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#llm=LoadOllamaLLM()\n",
    "llm=LoadGoogleLLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0551b555",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "De acuerdo al contexto proporcionado, si ingresas un autovector como vector inicial en el método de la potencia, el proceso se simplifica significativamente. \n",
      "\n",
      "El método de la potencia, como se explica, converge al autovector dominante (el asociado al autovalor de mayor valor absoluto) a través de sucesivas premultiplicaciones de un vector inicial por la matriz `A`.  Si el vector inicial `x` ya es un autovector `v_1` asociado al autovalor dominante `λ_1`, entonces:\n",
      "\n",
      "`A x = A v_1 = λ_1 v_1 = λ_1 x`\n",
      "\n",
      "Cada iteración del método simplemente multiplicará el vector `x` por el autovalor `λ_1`.  El vector permanecerá en la dirección del autovector `v_1` y el cociente `x_{k+1}(j) / x_k(j)` convergerá inmediatamente a `λ_1` sin necesidad de múltiples iteraciones.  El escalamiento (normalización) seguirá siendo necesario para evitar problemas de overflow o underflow, pero la convergencia será mucho más rápida y directa.\n",
      "\n",
      "---\n",
      "\n",
      "**TAREAS ACCIONABLES / PREGUNTAS DE REFLEXIÓN:**\n",
      "\n",
      "1.  **Considera una matriz A con autovalores λ1 = 5, λ2 = -2, λ3 = 1.** Si eliges como vector inicial el autovector asociado a λ1, ¿cuántas iteraciones crees que necesitarías para obtener una aproximación precisa de λ1 usando el método de la potencia? ¿Por qué?\n",
      "2.  **¿Qué sucedería si el vector inicial no fuera exactamente un autovector, sino una combinación lineal de autovectores?** ¿Cómo afectaría esto a la velocidad de convergencia?\n",
      "3.  **Relaciona este comportamiento con la idea de \"autovector dominante\" y cómo el método de la potencia explota esta propiedad.** ¿Por qué es importante que el autovalor dominante tenga un valor absoluto mayor que los demás?\n"
     ]
    }
   ],
   "source": [
    "#Uso de herramienta\n",
    "query=\"Que pasa si ingreso un autovector como vector inicial en el metodo de la potencia?\"\n",
    "\n",
    "response=ProcessInput(query,base_retriever,llm)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
